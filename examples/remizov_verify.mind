// Copyright 2025-2026 STARGA Inc.
// Licensed under the Apache License, Version 2.0
//
// Remizov Solver Verification Suite
//
// Validates the Remizov ODE solver against known analytical solutions:
//
// Test 1: Exponential decay (constant coefficients)
//         f''(x) - lambda*f(x) = -g(x) has Green's function solution
//
// Test 2: Euler-Cauchy equation
//         x^2 f''(x) + x f'(x) - f(x) = 0 has power-law solutions
//
// Test 3: Airy-type equation
//         f''(x) - x*f(x) = 0 (near Airy, but with source term)
//
// Test 4: Convergence rate O(1/n)
//         Verify error halves when n_iter doubles
//
// Test 5: Lambda sensitivity
//         Larger lambda -> smaller solution norm (more damping)

import std.math;
import std.tensor;

// ============================================================================
// Shared utilities
// ============================================================================

fn linspace(start: f64, end: f64, n: i32) -> tensor<f64[N]> {
    let step = (end - start) / (n - 1) as f64;
    let grid: tensor<f64[N]> = tensor.zeros[f64, (n,)];
    for i in 0..n {
        grid[i] = start + (i as f64) * step;
    }
    return grid;
}

fn interp_linear(x_grid: tensor<f64[N]>, y_grid: tensor<f64[N]>,
                 n: i32, x_query: f64) -> f64 {
    let x_min = x_grid[0];
    let x_max = x_grid[n - 1];
    if x_query <= x_min { return y_grid[0]; }
    if x_query >= x_max { return y_grid[n - 1]; }
    let step = (x_max - x_min) / (n - 1) as f64;
    let idx_f = (x_query - x_min) / step;
    let idx = idx_f as i32;
    if idx >= n - 1 { return y_grid[n - 1]; }
    let t = idx_f - (idx as f64);
    return y_grid[idx] * (1.0 - t) + y_grid[idx + 1] * t;
}

fn gauss_laguerre_nodes_32() -> (tensor<f64[32]>, tensor<f64[32]>) {
    let nodes: tensor<f64[32]> = [
        0.04448936583326,  0.23452610951961,  0.57688462930188,  1.07244875381782,
        1.72240877231768,  2.52833670642579,  3.49221338556548,  4.61645676974976,
        5.90395850417424,  7.35812673318624,  8.98294092421260, 10.78301863254472,
        12.76369798288079, 14.93113975552256, 17.29245433671532, 19.85586237537753,
        22.63089578245498, 25.62863602245921, 28.86210181632637, 32.34662915396487,
        36.10003201710083, 40.14539087991025, 44.51084695665178, 49.23221903498770,
        54.35529462706445, 59.94214052456898, 66.07764919526498, 72.88080035974944,
        80.52493710494128, 89.30314212536448, 99.88923568498693, 113.69397484942860
    ];
    let weights: tensor<f64[32]> = [
        0.11405028393994,  0.26114369910692,  0.39491839613498,  0.50633297605388,
        0.58656244033913,  0.62862456092304,  0.62853611776418,  0.58558127293698,
        0.50271293293702,  0.38668846695345,  0.25755230604698,  0.14484433894272,
        0.06728870721018,  0.02503059878258,  0.00726628914072,  0.00160068088993,
        0.00025655993407,  0.00002869561568,  0.00000210889288,  0.00000009506372,
        0.00000000244637,  0.00000000003202,  0.00000000000019,  0.00000000000000,
        0.00000000000000,  0.00000000000000,  0.00000000000000,  0.00000000000000,
        0.00000000000000,  0.00000000000000,  0.00000000000000,  0.00000000000000
    ];
    return (nodes, weights);
}

fn apply_shift_operator(
    x_grid: tensor<f64[N]>, h: tensor<f64[N]>, n_grid: i32,
    a_vals: tensor<f64[N]>, b_vals: tensor<f64[N]>, c_vals: tensor<f64[N]>,
    dt: f64
) -> tensor<f64[N]> {
    let h_new: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    for i in 0..n_grid {
        let xi = x_grid[i];
        let shift_diff = 2.0 * sqrt(a_vals[i] * dt);
        let shift_drift = 2.0 * b_vals[i] * dt;
        let h_plus  = interp_linear(x_grid, h, n_grid, xi + shift_diff);
        let h_minus = interp_linear(x_grid, h, n_grid, xi - shift_diff);
        let h_drift = interp_linear(x_grid, h, n_grid, xi + shift_drift);
        h_new[i] = 0.25 * h_plus + 0.25 * h_minus + 0.5 * h_drift + dt * c_vals[i] * h[i];
    }
    return h_new;
}

fn remizov_solve(
    a_vals: tensor<f64[N]>, b_vals: tensor<f64[N]>, c_vals: tensor<f64[N]>,
    g_vals: tensor<f64[N]>, x_grid: tensor<f64[N]>,
    lambda: f64, n_grid: i32, n_iter: i32, n_quad: i32
) -> tensor<f64[N]> {
    let (nodes, weights) = gauss_laguerre_nodes_32();
    let f_sol: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let n_eff = if n_quad > 32 { 32 } else { n_quad };

    for k in 0..n_eff {
        let w_k = weights[k];
        if w_k < 1e-15 { continue; }
        let t_k = nodes[k] / lambda;
        let dt = t_k / (n_iter as f64);
        let h = g_vals;
        for iter in 0..n_iter {
            h = apply_shift_operator(x_grid, h, n_grid, a_vals, b_vals, c_vals, dt);
        }
        for i in 0..n_grid {
            f_sol[i] = f_sol[i] + (w_k / lambda) * h[i];
        }
    }
    return f_sol;
}

// ============================================================================
// Test Helpers
// ============================================================================

fn max_abs_error(a: tensor<f64[N]>, b: tensor<f64[N]>, n: i32) -> f64 {
    let max_err = 0.0;
    for i in 0..n {
        let err = abs(a[i] - b[i]);
        if err > max_err { max_err = err; }
    }
    return max_err;
}

fn l2_error(a: tensor<f64[N]>, b: tensor<f64[N]>, n: i32) -> f64 {
    let sum_sq = 0.0;
    for i in 0..n {
        let d = a[i] - b[i];
        sum_sq = sum_sq + d * d;
    }
    return sqrt(sum_sq / (n as f64));
}

// ============================================================================
// Test 1: Constant Coefficients — Exponential Decay
// ============================================================================
//
// ODE: f''(x) - lambda*f(x) = -exp(-x^2)
// a(x)=1, b(x)=0, c(x)=0
//
// Analytical (Green's function):
//   f(x) = (1/(2*mu)) * integral exp(-mu*|x-y|) exp(-y^2) dy
//   where mu = sqrt(lambda)

fn test_constant_coefficients() {
    print("--- Test 1: Constant Coefficients ---");
    let n_grid = 200;
    let lambda = 4.0;
    let mu = sqrt(lambda);  // = 2.0
    let x_grid = linspace(-5.0, 5.0, n_grid);

    let a_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];
    let b_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let c_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let g_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    for i in 0..n_grid {
        g_vals[i] = exp(-x_grid[i] * x_grid[i]);
    }

    // Numerical solution
    let f_num = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                              lambda, n_grid, 500, 24);

    // Analytical solution via numerical integration of Green's function
    // f(x) = (1/(2*mu)) * integral_{-inf}^{inf} exp(-mu*|x-y|) exp(-y^2) dy
    let f_analytical: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let y_grid = linspace(-8.0, 8.0, 2000);
    let dy = 16.0 / 1999.0;

    for i in 0..n_grid {
        let xi = x_grid[i];
        let integral = 0.0;
        for j in 0..2000 {
            let yj = y_grid[j];
            integral = integral + exp(-mu * abs(xi - yj)) * exp(-yj * yj) * dy;
        }
        f_analytical[i] = integral / (2.0 * mu);
    }

    let err = max_abs_error(f_num, f_analytical, n_grid);
    let l2 = l2_error(f_num, f_analytical, n_grid);

    print("  Max absolute error: ", err);
    print("  L2 error:           ", l2);
    print("  PASS:", err < 0.05);
}

// ============================================================================
// Test 2: Variable Coefficients — Drift Term
// ============================================================================
//
// ODE: f''(x) + x*f'(x) - lambda*f(x) = -1
// a(x)=1, b(x)=x, c(x)=0
//
// No closed-form, but we verify self-consistency:
// the solution at two resolutions should converge.

fn test_variable_drift() {
    print("\n--- Test 2: Variable Drift b(x)=x ---");
    let n_grid = 150;
    let lambda = 3.0;
    let x_grid = linspace(-3.0, 3.0, n_grid);

    let a_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];
    let b_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let c_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let g_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];

    for i in 0..n_grid {
        b_vals[i] = x_grid[i];
    }

    // Solve at two different n_iter values
    let f_low  = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                               lambda, n_grid, 200, 20);
    let f_high = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                               lambda, n_grid, 800, 20);

    let diff = max_abs_error(f_low, f_high, n_grid);
    print("  Difference (n=200 vs n=800): ", diff);
    print("  Self-consistency PASS:", diff < 0.02);

    // Check symmetry: b(x)=x is odd, g(x)=1 is even -> f should be even
    let symmetry_err = 0.0;
    for i in 0..(n_grid / 2) {
        let err = abs(f_high[i] - f_high[n_grid - 1 - i]);
        if err > symmetry_err { symmetry_err = err; }
    }
    print("  Symmetry error:     ", symmetry_err);
    print("  Symmetry PASS:", symmetry_err < 0.01);
}

// ============================================================================
// Test 3: Reaction Term — Damped Potential
// ============================================================================
//
// ODE: f''(x) + (cos(x) - lambda)*f(x) = -exp(-x^2)
// a(x)=1, b(x)=0, c(x)=cos(x)
// lambda must be > sup|c(x)| = 1.0

fn test_reaction_term() {
    print("\n--- Test 3: Reaction c(x)=cos(x) ---");
    let n_grid = 200;
    let lambda = 3.0;   // > 1.0 = sup|cos(x)|
    let x_grid = linspace(-5.0, 5.0, n_grid);

    let a_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];
    let b_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let c_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let g_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];

    for i in 0..n_grid {
        c_vals[i] = cos(x_grid[i]);
        g_vals[i] = exp(-x_grid[i] * x_grid[i]);
    }

    let f_sol = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                              lambda, n_grid, 500, 24);

    // Basic sanity checks
    // 1. Solution should be finite and well-behaved
    let max_val = 0.0;
    for i in 0..n_grid {
        if abs(f_sol[i]) > max_val { max_val = abs(f_sol[i]); }
    }
    print("  Max |f(x)|:         ", max_val);
    print("  Bounded PASS:", max_val < 10.0);

    // 2. Solution should be symmetric (c and g are even, b=0)
    let sym_err = 0.0;
    for i in 0..(n_grid / 2) {
        let err = abs(f_sol[i] - f_sol[n_grid - 1 - i]);
        if err > sym_err { sym_err = err; }
    }
    print("  Symmetry error:     ", sym_err);
    print("  Symmetry PASS:", sym_err < 0.01);

    // 3. Solution should be positive (g > 0, Green's kernel positive for lambda large enough)
    let min_val = f_sol[0];
    for i in 0..n_grid {
        if f_sol[i] < min_val { min_val = f_sol[i]; }
    }
    print("  Min f(x):           ", min_val);
    print("  Positivity PASS:", min_val > -0.01);
}

// ============================================================================
// Test 4: Convergence Rate O(1/n)
// ============================================================================
//
// The Remizov formula has error O(1/(n * (lambda - ||c||)^3)).
// Doubling n_iter should approximately halve the error.

fn test_convergence_rate() {
    print("\n--- Test 4: O(1/n) Convergence Rate ---");
    let n_grid = 100;
    let lambda = 4.0;
    let x_grid = linspace(-5.0, 5.0, n_grid);

    let a_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];
    let b_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let c_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let g_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    for i in 0..n_grid {
        g_vals[i] = exp(-x_grid[i] * x_grid[i]);
    }

    // Reference with very high n_iter
    let f_ref = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                              lambda, n_grid, 4000, 24);

    let n_values = [50, 100, 200, 400, 800, 1600];
    let prev_err = 0.0;

    for n in n_values {
        let f_n = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                                lambda, n_grid, n, 24);
        let err = max_abs_error(f_n, f_ref, n_grid);

        if prev_err > 0.0 {
            let ratio = prev_err / err;
            print("  n_iter=", n, "  error=", err, "  ratio=", ratio);
        } else {
            print("  n_iter=", n, "  error=", err);
        }
        prev_err = err;
    }

    print("  Expected ratio ≈ 2.0 (doubling n halves error)");
}

// ============================================================================
// Test 5: Lambda Sensitivity
// ============================================================================
//
// Larger lambda means stronger damping -> smaller solution norm.
// ||f||_inf should decrease roughly as 1/lambda for large lambda.

fn test_lambda_sensitivity() {
    print("\n--- Test 5: Lambda Sensitivity ---");
    let n_grid = 100;
    let x_grid = linspace(-5.0, 5.0, n_grid);

    let a_vals: tensor<f64[N]> = tensor.ones[f64, (n_grid,)];
    let b_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let c_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    let g_vals: tensor<f64[N]> = tensor.zeros[f64, (n_grid,)];
    for i in 0..n_grid {
        g_vals[i] = exp(-x_grid[i] * x_grid[i]);
    }

    let lambdas = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0];

    for lam in lambdas {
        let f_sol = remizov_solve(a_vals, b_vals, c_vals, g_vals, x_grid,
                                  lam, n_grid, 500, 24);

        let max_f = 0.0;
        for i in 0..n_grid {
            if abs(f_sol[i]) > max_f { max_f = abs(f_sol[i]); }
        }
        print("  lambda=", lam, "  ||f||_inf=", max_f,
              "  lambda*||f||=", lam * max_f);
    }
    print("  Expected: lambda*||f|| should stabilize for large lambda");
}

// ============================================================================
// Main: Run All Tests
// ============================================================================

fn main() {
    print("MIND Remizov Solver — Verification Suite");
    print("=========================================\n");

    test_constant_coefficients();
    test_variable_drift();
    test_reaction_term();
    test_convergence_rate();
    test_lambda_sensitivity();

    print("\n=========================================");
    print("All tests completed.");
}
